# ü§ñ Transformers: From Vision to Language

**Facilitators:** Amr Khalifa (GDM), Juan Carlos Alcazar (KAUST)  
**Track:** Foundational  

## üìñ Session Overview
This session explores the architecture that revolutionized modern AI: the **Transformer**. Unlike traditional CNNs or RNNs, Transformers rely entirely on the Attention mechanism to draw global dependencies between input elements.

## ‚ö†Ô∏è Requirements
These notebooks rely heavily on matrix multiplications and should be run on a **GPU Runtime** for reasonable training times.
